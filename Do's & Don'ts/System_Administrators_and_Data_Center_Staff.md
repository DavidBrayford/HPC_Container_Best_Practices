# Do’s 
It is important for the data center staff to understand the hardware, software and policies of the data center and that of the specific HPC clusters that will be used for executing containerized workflows, as well as having a understanding of HPC container technologies. Otherwise they will not be able to develop good processes needed to successfully deploy containerized workflows on specific clusters within their data center.

The data center also needs to provide a HPC container building environment to enable the workflows to be built and tested on the same hardware and software as the clusters that will be used to deploy the container images. This potentially reduces the amount of time and effort required to resolve
any issues arising from the incorrect building of the container image for a specific HPC cluster environment.

It is a good idea to produce a workflow diagrams for how you expect the container will be deployed on the specific HPC clusters. This makes it easier for the data center staff to better understand how the system is configured for the deployment of the containerized HPC workflows, which is extremely useful if the person or persons who manage the HPC container service are unavailable for a period of time and an urgent task is need to be done before they are available.

Providing template recipes for every HPC cluster supported is very useful as it can minimize issues when executing the containerized workflow, which are related to an incorrectly configured container image for the specific HPC cluster. For example, having a verified recipe that correctly installs and
configures the high-speed network technologies and communication infrastructure. As well as ensuring that the MPI libraries and environment is optimally configured. In addition to correctly configuring the accelerator/GPU software within the container to enable the containerized workflow to use the GPU’s and finally setting up the mounting of the host directories within the container. This makes it much quicker and easier for the user to deploy their containerized workflows images on the specific cluster. It will also reduce the amount of time and effort of the data center staff in helping users to correctly setup their containerized workflow images. Remember that it is highly unlikely that the end-user of the HPC system has configured an MPI environment, or a network or a GPU on a HPC cluster.

Providing container recipes and container images in a verified container registry for typical or standard workflows used on the HPC cluster. Is a good idea as the data center staff can point the user to an existing verified container image, which the user can use rather than having the user or data center staff build the container image and potentially introducing errors. Finally, it is important to provide detailed and clear documentation and HowTos guides along with a set of examples for each HPC cluster. Not only to help the end-users, but also, help train the data center staff on how to setup and manage the HPC container service.

# Don’ts
It is extremely important that the data center doesn’t provide a service their staff don’t understand. As it will lead to unexpected issues to frequently occur, which are difficult to predict, avoid and resolve easily. Also, it will result in the data center support staff spending a lot more time and
effort supporting users than expected.  In addition, the end users will complain about the poor quality of service, which might result in the user moving their work to another data center.

Finally, don’t reinvent the wheel. Often you will find that someone else has already encountered the problems you are facing and have come up with solutions. The mechanisms they have developed might not be ideal for your situation, but it is likely very close and might only require a few modifications to make it work for your needs. Or at the very least provide some insights on how to approach and tackle the issues you are facing. It’s good to talk with folks who are working on containers at other data centers to share experiences and come up with a common approach to deploying containers on clusters.
